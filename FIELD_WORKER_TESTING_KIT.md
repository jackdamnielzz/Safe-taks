# Field Worker Mobile Usability Testing Kit - SafeWork Pro

## Testing Session Structure

### Session Overview
- **Duration**: 45-60 minutes per participant
- **Format**: One-on-one testing with facilitator observation
- **Recording**: Screen recording + audio + written notes
- **Environment**: Construction site or simulated field conditions

### Session Flow
1. **Introduction & Consent** (5 minutes)
2. **Pre-Test Questionnaire** (5 minutes)
3. **App Installation & Setup** (5 minutes)
4. **Task-Based Testing** (20-25 minutes)
5. **Post-Test Questionnaire** (10 minutes)
6. **Debrief & Discussion** (5 minutes)

## 1. Pre-Test Questionnaire

### Participant Information
**Date**: ____________________ **Session ID**: ____________________

**Participant Code**: FW-___ **Facilitator**: ____________________

1. **Demographics**
   - Age: _____ years old
   - Gender: □ Male □ Female □ Prefer not to say
   - Job Title: ____________________
   - Years in current role: _____
   - Trade/Specialty: ____________________

2. **Technology Experience**
   - What smartphone do you use? □ iPhone □ Android □ Other: _____
   - How comfortable are you with mobile apps? (1-5 scale)
     □ 1 - Not comfortable at all □ 2 □ 3 □ 4 □ 5 - Very comfortable

3. **Current Safety Practices**
   - What safety documentation methods do you currently use?
     □ Paper forms □ Digital forms (tablet/laptop) □ Mobile apps □ Other: _____
   - How often do you complete safety assessments? □ Daily □ Weekly □ Monthly □ Rarely

4. **Work Environment**
   - What type of work environment do you primarily work in?
     □ Construction sites □ Industrial facilities □ Both □ Other: _____
   - Do you typically work outdoors? □ Yes □ No □ Sometimes
   - What PPE do you regularly wear? (Check all that apply)
     □ Safety glasses □ Hard hat □ Work gloves □ High-vis vest □ Other: _____

5. **Mobile Device Usage at Work**
   - How often do you use your phone for work tasks? □ Never □ Rarely □ Sometimes □ Often □ Always
   - What are the biggest challenges with using mobile devices on site?
     ________________________________________________________________________________
     ________________________________________________________________________________

## 2. Testing Scenarios & Tasks

### Scenario 1: Routine LMRA Execution (Primary Workflow)
**Context**: Start of workday, normal conditions, fully connected

**Tasks**:
1. **App Launch & Navigation**
   - Find and launch SafeWork Pro from home screen
   - Navigate to "Start LMRA" (should take <10 seconds)
   - Expected: Large, prominent "Start LMRA" button on home screen

2. **Location Verification**
   - Confirm current location with GPS
   - Accept/override location if needed
   - Expected: Clear location display, easy accept/override buttons

3. **Weather Check**
   - Review current weather conditions
   - Confirm if work can proceed safely
   - Expected: Clear weather info, prominent continue/stop buttons

4. **Team Member Check-in**
   - Add 3-4 team members to LMRA session
   - Verify each person's competency/certifications
   - Expected: QR code scanning or manual search, clear status indicators

5. **Equipment Verification**
   - Scan equipment QR codes (3-4 items)
   - Check inspection status and expiry dates
   - Expected: Camera opens quickly, clear scan feedback

6. **Hazard Identification**
   - Review work area for potential hazards
   - Select from common hazards list (touch gloves on)
   - Add photo documentation for each hazard
   - Expected: Large touch targets, easy photo capture

7. **Risk Assessment**
   - Assess risk level for each identified hazard
   - Use simplified Kinney & Wiruth interface
   - Expected: Clear risk indicators, easy adjustment

8. **Control Measures**
   - Select appropriate control measures
   - Assign responsibilities to team members
   - Expected: Clear hierarchy of controls, easy assignment

9. **Final Decision**
   - Make go/no-go decision
   - Digital signature capture (with gloves)
   - Submit LMRA for supervisor review
   - Expected: Clear decision buttons, signature works with gloves

**Time Target**: Complete workflow in <5 minutes
**Success Criteria**: 100% completion without assistance

### Scenario 2: Emergency Stop Work Situation
**Context**: Hazard discovered during routine inspection, urgent situation

**Tasks**:
1. **Quick Access to Stop Work**
   - From any screen, access "Stop Work" function
   - Should be available within 2 taps maximum
   - Expected: Prominent emergency button, always visible

2. **Immediate Hazard Documentation**
   - Capture photo of hazard (camera should open immediately)
   - Select hazard category and severity level
   - Expected: Camera launches in <2 seconds, clear category selection

3. **Team Notification**
   - Send immediate notification to all team members
   - Add brief description of hazard and required actions
   - Expected: One-tap team notification, clear status feedback

4. **Supervisor Alert**
   - Generate supervisor notification with full details
   - Include location, photos, and urgency level
   - Expected: Automatic supervisor alert, confirmation of delivery

**Time Target**: Complete stop work process in <2 minutes
**Success Criteria**: 100% completion, clear urgency indicators

### Scenario 3: Offline Operation & Sync
**Context**: Poor network area, LMRA completion required

**Tasks**:
1. **Offline LMRA Creation**
   - Complete full LMRA workflow in offline mode
   - Capture photos and detailed notes
   - Expected: Clear offline indicators, smooth operation

2. **Network Recovery**
   - Simulate network reconnection
   - Verify automatic data synchronization
   - Check for any sync errors or conflicts
   - Expected: Automatic sync, clear sync status, error handling

3. **Data Verification**
   - Confirm all data uploaded successfully
   - Check photo quality and completeness
   - Expected: Complete data integrity, clear sync confirmation

**Success Criteria**: 100% data preservation and sync

## 3. During-Test Observation Checklist

### Usability Observations
- [ ] **Touch Target Success**: Can user tap buttons accurately on first try?
- [ ] **Glove Compatibility**: Does interface work well with work gloves?
- [ ] **Screen Readability**: Is content readable in bright sunlight?
- [ ] **One-Handed Operation**: Can user complete tasks with one hand?
- [ ] **Navigation Clarity**: Is it clear where to go next?
- [ ] **Error Recovery**: When errors occur, can user easily recover?
- [ ] **Performance**: Does app respond quickly to interactions?
- [ ] **Visual Feedback**: Are button presses and actions clearly indicated?

### Field-Specific Observations
- [ ] **PPE Interference**: Does safety equipment interfere with device use?
- [ ] **Environmental Challenges**: Impact of weather, noise, lighting?
- [ ] **Cognitive Load**: Does user seem overwhelmed or confused?
- [ ] **Safety Focus**: Does design support safety priorities?
- [ ] **Efficiency**: Is workflow faster than current paper-based methods?

### Critical Incident Tracking
- [ ] **Safety-Critical Issues**: Any usability problems that could affect safety?
- [ ] **Task Failures**: Any tasks that couldn't be completed?
- [ ] **Workarounds**: Did user develop alternative methods to complete tasks?

## 4. Post-Test Questionnaire

### User Experience Rating (1-5 Scale)

**1 = Strongly Disagree, 5 = Strongly Agree**

1. **Ease of Use**
   - The app was easy to learn how to use
   - Navigation between screens was intuitive
   - I could find the functions I needed quickly
   - The app responded quickly to my inputs

2. **Mobile Optimization**
   - Buttons and links were easy to tap with my fingers
   - Text was easy to read on the mobile screen
   - The app worked well with the gloves I wear at work
   - The screen was readable in bright sunlight

3. **Field Worker Suitability**
   - The app is suitable for use on construction sites
   - I felt confident using the app in my work environment
   - The app helped me complete safety tasks more efficiently
   - I would prefer this over paper-based methods

4. **Safety Integration**
   - Safety features were prominent and easy to access
   - The app helped me identify and document hazards better
   - Emergency/stop work functions were easy to find and use
   - I trust the app for critical safety documentation

5. **Offline Functionality**
   - The app worked well when I had no internet connection
   - I was confident my data would be saved offline
   - Synchronization after reconnection worked smoothly
   - I understood when I was working offline vs online

### Open-Ended Feedback

1. **What did you like most about the mobile app?**
   ________________________________________________________________________________
   ________________________________________________________________________________

2. **What did you like least or found frustrating?**
   ________________________________________________________________________________
   ________________________________________________________________________________

3. **What features would you add or change for field workers?**
   ________________________________________________________________________________
   ________________________________________________________________________________

4. **How does this compare to your current safety documentation process?**
   ________________________________________________________________________________
   ________________________________________________________________________________

5. **Would you recommend this app to other field workers? Why/why not?**
   ________________________________________________________________________________
   ________________________________________________________________________________

### Feature Priority Ranking
Please rank the following features by importance for your work (1 = Most Important):

- [ ] LMRA execution and documentation
- [ ] Hazard identification and photo capture
- [ ] Team member and equipment verification
- [ ] Offline functionality
- [ ] Emergency stop work notifications
- [ ] Integration with existing safety systems
- [ ] Real-time supervisor notifications
- [ ] Historical safety records access

## 5. SUS (System Usability Scale) Questionnaire

**Please rate your agreement with each statement:**

1. I think that I would like to use this system frequently
   □ 1 □ 2 □ 3 □ 4 □ 5

2. I found the system unnecessarily complex
   □ 1 □ 2 □ 3 □ 4 □ 5

3. I thought the system was easy to use
   □ 1 □ 2 □ 3 □ 4 □ 5

4. I think that I would need the support of a technical person to be able to use this system
   □ 1 □ 2 □ 3 □ 4 □ 5

5. I found the various functions in this system were well integrated
   □ 1 □ 2 □ 3 □ 4 □ 5

6. I thought there was too much inconsistency in this system
   □ 1 □ 2 □ 3 □ 4 □ 5

7. I would imagine that most people would learn to use this system very quickly
   □ 1 □ 2 □ 3 □ 4 □ 5

8. I found the system very cumbersome to use
   □ 1 □ 2 □ 3 □ 4 □ 5

9. I felt very confident using the system
   □ 1 □ 2 □ 3 □ 4 □ 5

10. I needed to learn a lot of things before I could get going with this system
    □ 1 □ 2 □ 3 □ 4 □ 5

## 6. Testing Environment Checklist

### Equipment Needed
- [ ] Test smartphone (iOS/Android mix)
- [ ] Work gloves (different thicknesses)
- [ ] Safety glasses (if applicable)
- [ ] Camera for recording session
- [ ] Audio recorder for participant comments
- [ ] Note-taking device for facilitator
- [ ] Backup battery/charger
- [ ] Test data (sample projects, team members)

### Environmental Conditions
- [ ] Lighting: Test in bright sunlight and shade
- [ ] Weather: If outdoors, note current conditions
- [ ] Noise Level: Background construction noise if on site
- [ ] Network: Test both online and offline modes
- [ ] Distractions: Minimize interruptions during testing

### Safety Considerations
- [ ] Site safety briefing completed
- [ ] Emergency procedures understood
- [ ] PPE requirements met for test location
- [ ] Insurance coverage confirmed
- [ ] Participant safety is priority over testing goals

## 7. Facilitator Guidelines

### Before Session
1. **Preparation**
   - Review participant background and customize scenarios if needed
   - Ensure all equipment is charged and working
   - Test the app on target device beforehand
   - Prepare test data and sample content

2. **Participant Briefing**
   - Explain purpose: "We're testing the mobile app, not your abilities"
   - Emphasize: "There are no wrong answers, be honest about difficulties"
   - Describe: "We'll ask you to complete realistic safety tasks"
   - Confirm: "You can stop at any time if needed"

### During Session
1. **Observation Style**
   - Stay neutral and non-judgmental
   - Take detailed notes on struggles and successes
   - Ask clarifying questions without leading
   - Allow participants to explore and make mistakes

2. **Assistance Protocol**
   - Only provide help if participant is completely stuck (>2 minutes)
   - Note when and why assistance was provided
   - Track if assistance was due to app issues vs learning curve

3. **Time Management**
   - Keep sessions to 45-60 minutes maximum
   - Prioritize critical workflows if time is limited
   - Allow breaks if participant needs them

### After Session
1. **Debrief Process**
   - Review what went well and what was challenging
   - Ask about specific likes/dislikes
   - Inquire about relevance to their actual work
   - Thank participant and explain next steps

2. **Data Organization**
   - Label all recordings and notes with session ID
   - Complete observation checklist immediately
   - Note any technical issues or environmental factors
   - Calculate SUS score and summarize key findings

## 8. Success Metrics by Scenario

### LMRA Execution Scenario
- **Task Completion**: 100% of participants complete workflow
- **Time Performance**: Average <5 minutes for full LMRA
- **Error Rate**: <5% errors requiring correction
- **Touch Success**: >95% first-attempt touch accuracy
- **Glove Compatibility**: 100% functionality with work gloves

### Emergency Stop Work Scenario
- **Access Time**: <30 seconds to initiate stop work
- **Notification Speed**: <1 minute for team notification
- **Photo Success**: 100% successful photo capture
- **Offline Reliability**: 100% functionality without network

### Overall Usability
- **SUS Score**: >80 (excellent usability)
- **Satisfaction**: >4/5 average satisfaction rating
- **Recommendation**: >80% would recommend to colleagues
- **Preference**: >70% prefer digital over paper methods

## 9. Troubleshooting Guide

### Common Issues & Solutions

#### Touch Interaction Problems
- **Issue**: Buttons hard to tap accurately
- **Solution**: Increase touch target sizes to 48px minimum
- **Prevention**: Test with gloves during development

#### Glove Compatibility Issues
- **Issue**: Interface doesn't work with work gloves
- **Solution**: Implement glove mode with larger touch targets
- **Prevention**: Design for 64px touch targets for gloved use

#### Sunlight Readability Problems
- **Issue**: Screen hard to read in bright sunlight
- **Solution**: Increase contrast ratios and font sizes
- **Prevention**: Test in outdoor conditions, use high-contrast design

#### Offline Functionality Issues
- **Issue**: App doesn't work without internet
- **Solution**: Improve offline indicators and caching
- **Prevention**: Comprehensive offline testing before release

#### Performance Issues
- **Issue**: App slow or unresponsive
- **Solution**: Optimize image loading and reduce bundle size
- **Prevention**: Performance testing on target devices

## 10. Data Analysis Framework

### Quantitative Analysis
- Calculate average scores for each rating scale
- Track completion rates and times by task
- Compare performance across different user groups
- Identify statistically significant differences

### Qualitative Analysis
- **Thematic Coding**: Group similar feedback into categories
- **Severity Assessment**: Critical, Major, Minor issue classification
- **Pattern Recognition**: Identify recurring usability problems
- **Priority Matrix**: Impact vs Frequency analysis

### Reporting Structure
1. **Executive Summary**: Key findings and recommendations
2. **Detailed Results**: Quantitative data and qualitative insights
3. **Issue Prioritization**: Ranked list of improvements needed
4. **Implementation Roadmap**: Phased improvement plan

---

**Document Version**: 1.0.0
**Last Updated**: ${new Date().toISOString()}
**Status**: ✅ Complete Testing Kit Ready for Field Testing